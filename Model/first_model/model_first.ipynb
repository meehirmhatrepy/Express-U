{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout,Dense,ReLU,Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>E:/Documents/GitHub/Express-U/data/preprocesse...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_paths labels\n",
       "0      E:/Documents/GitHub/Express-U/data/preprocesse...      1\n",
       "1      E:/Documents/GitHub/Express-U/data/preprocesse...      1\n",
       "2      E:/Documents/GitHub/Express-U/data/preprocesse...      1\n",
       "3      E:/Documents/GitHub/Express-U/data/preprocesse...      1\n",
       "4      E:/Documents/GitHub/Express-U/data/preprocesse...      1\n",
       "...                                                  ...    ...\n",
       "41995  E:/Documents/GitHub/Express-U/data/preprocesse...      Z\n",
       "41996  E:/Documents/GitHub/Express-U/data/preprocesse...      Z\n",
       "41997  E:/Documents/GitHub/Express-U/data/preprocesse...      Z\n",
       "41998  E:/Documents/GitHub/Express-U/data/preprocesse...      Z\n",
       "41999  E:/Documents/GitHub/Express-U/data/preprocesse...      Z\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/Documents/GitHub/Express-U/data/preprocessed/canny_labels.csv',index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train,X_Test = train_test_split(df,train_size=0.8,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_image_generator = ImageDataGenerator(rescale=1/255,\n",
    "                                        zoom_range=0.5,\n",
    "                                        brightness_range=[0.6,1.0],\n",
    "                                        rotation_range=20,\n",
    "                                        validation_split=0.1)\n",
    "Test_image_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30240 validated image filenames belonging to 35 classes.\n",
      "Found 3360 validated image filenames belonging to 35 classes.\n",
      "Found 8400 validated image filenames belonging to 35 classes.\n"
     ]
    }
   ],
   "source": [
    "Train_Set = Train_image_generator.flow_from_dataframe(dataframe=X_Train,\n",
    "                                                   x_col=\"file_paths\",\n",
    "                                                   y_col=\"labels\",\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   color_mode=\"grayscale\",\n",
    "                                                   subset=\"training\")\n",
    "\n",
    "Validation_Set = Train_image_generator.flow_from_dataframe(dataframe=X_Train,\n",
    "                                                   x_col=\"file_paths\",\n",
    "                                                   y_col=\"labels\",\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   color_mode=\"grayscale\",\n",
    "                                                   subset=\"validation\")\n",
    "\n",
    "\n",
    "Test_Set = Test_image_generator.flow_from_dataframe(dataframe=X_Test,\n",
    "                                                   x_col=\"file_paths\",\n",
    "                                                   y_col=\"labels\",\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   color_mode=\"grayscale\",\n",
    "                                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Set.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputshape = (256,256,1)\n",
    "outputshape = 35\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=inputshape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(outputshape,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 524288)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               67108992  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2275      \n",
      "=================================================================\n",
      "Total params: 67,378,531\n",
      "Trainable params: 67,378,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 268s 34s/step - loss: 3.5413 - accuracy: 0.0273 - val_loss: 3.4513 - val_accuracy: 0.0820\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 284s 37s/step - loss: 3.1595 - accuracy: 0.1602 - val_loss: 2.9538 - val_accuracy: 0.2227\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 260s 33s/step - loss: 2.6621 - accuracy: 0.2891 - val_loss: 2.7521 - val_accuracy: 0.2852\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 252s 32s/step - loss: 2.4483 - accuracy: 0.3438 - val_loss: 2.1022 - val_accuracy: 0.4414\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 244s 31s/step - loss: 2.1693 - accuracy: 0.4219 - val_loss: 2.0139 - val_accuracy: 0.4844\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 250s 32s/step - loss: 1.8732 - accuracy: 0.5195 - val_loss: 1.7951 - val_accuracy: 0.5625\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 247s 32s/step - loss: 1.6109 - accuracy: 0.5391 - val_loss: 1.5756 - val_accuracy: 0.5664\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 217s 27s/step - loss: 1.5307 - accuracy: 0.5703 - val_loss: 1.2932 - val_accuracy: 0.6562\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 201s 26s/step - loss: 0.9847 - accuracy: 0.7188 - val_loss: 1.0681 - val_accuracy: 0.6992\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 199s 25s/step - loss: 0.9152 - accuracy: 0.7344 - val_loss: 0.8647 - val_accuracy: 0.7422\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Train_Set,epochs=10,steps_per_epoch=(Train_Set.image_shape[0] // 32),validation_steps=(Validation_Set.image_shape[0] // 32),batch_size=32,verbose=1,validation_data=Validation_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.5412585735321045,\n",
       "  3.1594512462615967,\n",
       "  2.6620888710021973,\n",
       "  2.448328971862793,\n",
       "  2.169344425201416,\n",
       "  1.8732231855392456,\n",
       "  1.610938549041748,\n",
       "  1.5306503772735596,\n",
       "  0.9847385883331299,\n",
       "  0.9151589274406433],\n",
       " 'accuracy': [0.02734375,\n",
       "  0.16015625,\n",
       "  0.2890625,\n",
       "  0.34375,\n",
       "  0.421875,\n",
       "  0.51953125,\n",
       "  0.5390625,\n",
       "  0.5703125,\n",
       "  0.71875,\n",
       "  0.734375],\n",
       " 'val_loss': [3.4512529373168945,\n",
       "  2.9537642002105713,\n",
       "  2.7520899772644043,\n",
       "  2.1021885871887207,\n",
       "  2.013854503631592,\n",
       "  1.795127272605896,\n",
       "  1.5756263732910156,\n",
       "  1.2932186126708984,\n",
       "  1.0681335926055908,\n",
       "  0.8646857738494873],\n",
       " 'val_accuracy': [0.08203125,\n",
       "  0.22265625,\n",
       "  0.28515625,\n",
       "  0.44140625,\n",
       "  0.484375,\n",
       "  0.5625,\n",
       "  0.56640625,\n",
       "  0.65625,\n",
       "  0.69921875,\n",
       "  0.7421875]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 50s 6s/step - loss: 0.2367 - accuracy: 0.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23673881590366364, 0.9296875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Test_Set,steps=(Test_Set.image_shape[0] // 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_canny.h5')\n",
    "model.save_weights('model_canny_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8a3b870b663af00ffaf2965646e614892b3bc390a9f2eaaf38e9628c0376dcf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
